\documentclass{article}

\title{LTS-IO}
\author{Stefan Blom and Jaco van de Pol}

\begin{document}

\maketitle

\begin{abstract}
In this paper, we explain the design and implementation of LTS-IO.
\end{abstract}

\section{Introduction}

The concept of the $\mu$CRL toolset is to generate the LTS.
If necessary apply bisimulation reduction. And subsequently
model check it. For simplicity, we assume that reduction is always used.
In that case there are two ways fo transfering data from the generator (producer)
to the reducer (consumer).
\begin{enumerate}
\item First, producer to disk. Then, disk to consumer.
\item Producer to consumer directly.
\end{enumerate}
We will show that in the first case the consumer is free to
read the data in any order it wants. In the second case, the consumer has to follow
the order determined by the producer.

\bigskip

Let us consider a distribtued setting with $W$ workers.
The natural way of writing the LTS in a distributed generator is to let each worker
write their transitions separately. This is reflected in the number of files used in
distributed file formats. The PBCG format uses one small meta file and $W$ data files.
The DIR format uses two small meta files and $3\cdot W^2$ data files.
The motivation for having so many files in the DIR format is that when there are many files,
it is easy for a worker to read the data it needs directly without the need for
information exchange procedures in a distributed application. The motivation for
PBCG to have $W$ is that because the BCG format is compressed, it is better for performance.
Moreover, writing to $W$ files means that they can be on $W$ different files systems.
This is very useful, when writing to local disks on the workers rather than to
a single shared file system.

The rate at which $\mu$CRL produces transition data is not very high,
so performance problems with writing were never seen. However, performance problems
can be seen while reading the LTS. To explain why, we consider the generic problem
of $N$ files on a single file system. If the file system has a good block
allocation algorihtm then no matter in which order the files were written,
they are more or less contiguous on the disk. If the block allocation algorithm is
too naive then the $N$ files will be fragmented and the fragment will be on
the disk more or less in the order they were written. In the former case, the optimal order
for reading is to read files sequentially. In the latter case the optimal order is
to read them in the order they were written. Nowadays it seems safe to assume that
the file system properly defragments files as they are written. (See task list.)
So we need to read the files sequentially. This is easy enough if every worker has one file locally
and also if each client can match the bandwidth of the server. However, when one uses
a clustered file system, the bandwidth of the server exceeds that of one client.
In this case we need to have all workers read in parallel and redistribute the data
among themselves.

When reading in parallel, we can completely overlap decompression and 
reading. When reading sequentially, we can only overlap decompression and
reading of the last files. If either decompression of the file server is fast,
the problem should be minor. However, if the file server is slow and
decompression is slow as well then there should be a problem. (See task list.)

Solution 1: Have an agent that when a client opens a file, reads the entire file
into memory and then serves reads in parallel with other opens. This can be a
problem if the files are very small. (Reads need to be 1MB or bigger for efficiency.)
It can also be a problem in case of large files where processing can overlap with
reading. A variant would be that the agent allocates big buffers (say 1MB each) for
each file opened and sequentializes reads of these buffers between clients.
In some cases a read ahead of the entire file might be best in some case just one
buffer read ahead is best. Because these buffers can live in the
memory of the client, it does not impose an unacceptable memory overhead.



Conclusion:
\begin{itemize}
\item Defragmentation seems to work so competitive($\equiv$interleaved) writing is OK.
\item Tests show that competitive reading is bad.
\item How about problems with collaborative($\equiv$sequentialized) reading?
\begin{itemize}
\item With a lot of files, it takes time and memory to buffer every file.
\\
Q: Do we need to be prepared for a 1000 segment DIR?
\\
A: Only if we are serious about on-disk generation, reduction and model checking.
\item If the files are too small, buffering doesn't work any more.
\\
This is real: e.g. src-x-y file compress really well and might end up being tiny.
However, a file format with 1 file per worker is safe in this respect and
sufficient unless we work with on-disk algorithms.
\\
To get around the small files problems multiple files have to be combined.
One way is to weave many small files into an archive.
\end{itemize}
\end{itemize}

\bigskip

The discussion above assumes that all files are on one (distributed) file system.
Moreover, in the case of a distributed file system it assumes that the files
themselves are distributed over sufficiently many block devices. That is,
every single read is assumed to count against one bandwidth resource.
However, if we are in a situtation where files are on different machines then
we may have a problem. For example consider a situation where we have $N$
workers generating $N$ files each on their local file system. Assume that
the next program to run needs one file from each server. If the read order
is that everyone reads the file from the first server first then the file from
the second server, etc. then we use merely $\frac{1}{N}^{\rm th}$ of the available
bandwidth. In this particular example we have a fixed distribution of
files over locations. So by using a different read order we can fix the problem.
If the localtions are not known in advance them a dynamically scheduled
read order has to be implemented. If the application loads everything into
memroy then we may hide this from the user by having an agent load the
files in the correct order and by having the  application read from
the agent. If the loading entire files into memory is not an option
then the application has to let an agent schedule the read order for it.


\section{Streaming an LTS between applications}


A stranded data stream, is a data stream into which several other
data streams have been merged. For example a transition stream
might have 4 strands: source, label, dest and table.
These would be written and read as follows:

\begin{verbatim}
void write_trans(int  src,ATerm  lbl,int  dst){
  write(source,src);
  write(label,put(T,lbl,&new));
  if(new) serialize(table,lbl);
  write(dest,dst);
}
int  read_trans (int *src,ATerm *lbl,int *dst){
  read(source,lbl);
  read(label,&idx);
  if (!T[idx]) deserialize(table,T+idx);
  read(dest,dst);
}
\end{verbatim}

There are two reasons for using separate strands. First, different streams use different compression
types. Second, if this is used in a distributed setting then the final destination of
the source strand might not be the same as that of the dest strand.

The reference implementation of strands is to translate a write on a strand to 
writing a tag, the length and the data in the stream. This induces a high overhead,
which can be reduced by buffering the strands. When buffering is applied it is important
that this does not introduce deadlocks. The is the reading side should use sufficiently large
buffers that read calls made in the same order as the write calls never lead to a deadlock.
To satisfy this requirement, one must be careful with compression. If one strand has a much higher compression ratio
than other then it is possible that the first block of this stream is delayed for a long time.
This problem can be avoided by compressing the stream rather than the strands, but 
that would make it impossible to use special compression techniques (such as differencing)
on the strands and it would also reduce parallellism (separate strands can be compressed by different threads).

\bigskip

If a stranded stream has to be written to disk then one can simply write the
data to disk without processing. This is simple, but it is difficult to access
the separate strands because one has to scan the entire file to find one strand.
One can also split the stream and write each strand to disk as a separate file.
This is also simple and allows easy acces to the separate strands.
When we do this, the stream order is of course lost unless we record it
in an extra file.
If access to separate strands is required and splitting is not an option then
a stranded stream can be transformed into an archive file. That is, data blocks
are aligned at block boundaries and some form of index structure is added.
For example, an archive could consist of a list of clusters.
A cluster would contain $N$ blocks. One of those would contain a list of
strands to which the other $N-1$ data blocks belong.

\bigskip

To enable distributed reading of stranded streams in files, it is necessary to
be able to find messages boundaries. (Think end of line in a text file.)
One could achieve this by letting every
block start with the offset of the starting point of the first message.

E.g. with 8 byte blocks the stream
\begin{verbatim}
H  e  l  l  o     W  o  r  l  d \n
0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
\end{verbatim}
becomes
\begin{verbatim}
H  e  l  l  o     W  o  5  r  l  d \n
0  1  2  3  4  5  6  7  0  1  2  3  4  5  6  7
\end{verbatim}
Because the first new message in the second block starts at offset 5 in that block.

\bigskip

{\em future work} In a distributed application, a strand can have multiple writers and multiple readers.
The writers may indicate a message boundary by calling mark. And they may indicate
a required order by calling barrier. The readers can read collectively in which case the message
are delivered to all readers in the same order. They can also read individually in which case
each message is delivered to precisely one reader. We need to specify when the readers
can switch from collective to individual and back. {\em end}

\section{Message based streams}

Many big files are of the form header record${}^*$ trailer.
Also it is quite often possible to process the records independently.
However, to do this independent processing one needs to find the
boundaries between records. This is trivial if the record length is fixed, but
becomes problematic if the records have variable length.

We identify two cases of variable length. One possible case is that records are separated
by using a character which is not otherwise used. For example, the lines of a UNIX text file
are separated by LF characters. Another case is the encoding of a list of variables length
records as a $($length data$)^*$ sequence. In the former case, we can select any block size
and search for boundaries. In the latter case, we can fix a block size in the header
and let every block start with the offset of the starting point of the first message.

E.g. with 8 byte blocks the stream
\begin{verbatim}
11 H  e  l  l  o     W  o  r  l  d
0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
\end{verbatim}
becomes
\begin{verbatim}
11 H  e  l  l  o     W  5  o  r  l  d
0  1  2  3  4  5  6  7  0  1  2  3  4  5  6  7
\end{verbatim}
Because the first new message in the second block starts at offset 5 in that block.

In the implementation we might have to allow not just 8 bit characters but also 16, 32 and 64 bit ones.
Likewise there is more than one way to encode the length of a record. Especially if it is allowed to
mix a message tag with the length.

Parallel reading needs a marking character or a fixed block size plus offsets.
When we also want to change the block size then we need to know how to split
a stream into messages. We also need to know that to add this coding to a continuous stream.


Thus, these two encodings lead to one additional call in the stream API:
\begin{itemize}
\item {\bf mark} which adds the record boundary string in case of a boundary string
and which tells the buffering mechanism how to set the initial offset.
(When a block is started the offset is initialized to 0 meaning no offset in block.
If mark is called then the offset is changed if it is the first one.
The end of the stream counts as a mark as well.)
\end{itemize}

\section{The IO layer}

Write synchronisation is not needed because the block allocation of the OS is good.
Read synchronisation is necessary. This is not a service provided by the OS.
It is provided by MPI2, but only for a single file. In any case there needs to be a
layer in between the application and the OS that sequentializes disk access.
To make full use of clustered file systems this layer has to be a distributed component.
A logical choice is an MPI layer because MPI-IO provides an efficient implementation
of the necessary joint reading of very large blocks.

MPI-IO itself is not enough: it does not offer efficient reading of separate files by separate workers.

Logically the agent layer is best seen as a separate process in a
client-agent-server stack. However, the implementation of the layer could be as
\begin{itemize}
\item A coroutine within the client
\item A separate thread within the client
\item Some thread in a separate process on the client
\item Some thread in a separate process on the server
\item A separate thread within the server
\item A coroutine within the server
\end{itemize}

The necessary operations are:
\begin{itemize}
\item Open a file for reading with $N$ readers total.
(If a file is to be read by many workers it is not smart to fetch it many times.)
This returns a stream handle.
\item Reading data from the stream handle.
\item Closing the stream handle.
\end{itemize}

Internally, the layer has a distributed cluster buffer.
When a read request for a stream is received it will be satisfied from the buffer if possible.
Otherwise an entire cluster will be read from disk. Possible read-ahead strategies are:
none, one, all. That is, wait for the read request, try to keep one cluster ahead of the reader or
read the entire file as soon as possible.

The layer could also take a more active approach by forwarding all block in a cluster to the client(s)
eagerly instead of on-demand. This could involve a flow-control mechanism to avoid overfeeding the client.


\section{The one-file option}

Advantages:
\begin{itemize}
\item If the archive is contiguous then reading from an archive can give you 100% performance.
Interleaving cluster sized reads will always have some performance penalty.
But if there is more than one user of the file system then that is the best possible result anyway.
\item More elegant during copying.
\end{itemize}
Disadvatages:
\begin{itemize}
\item Need tools to access files in archive.
\item If the file system cluster size is bigger than the archive block size then
reading one file from the file system is more efficient than reading one file from the archive.
\end{itemize}

\section{out-of-order reading}

If a server has a list of clusters wanted by each user then it can schedule the reads of
those clusters to optimize throughput. For example if one user want a long list of clusters
and another user repeatedly asks for specific clusters then to be fair to the second user those
specific requests have to be honoured. By being able to give arbitrary blocks from the list to
the first user the length of the seeks can be minimized: i.e. in between serving two requests
from the second user the server could just give the first client a few clusters from
locations that are located in between the two requests from the first user.

\section{Task list}

\begin{itemize}
\item Run experiments to assess the quality of block allocation algorithms on various
file system implementations by measuring the speed of read and write orders and number of files.
\item Run experiments to asses the effect of the cluster size on sequentialized reads.
(E.g. tweety: 4k: 8.53MB/s; 256k: 11.66MB/s; 1024k: 19.39MB/s; $\infty$: 24.53MB/s).
\item Run experiments to assess compression/decompression speeds for gzip/bzip2/lzo
to be able to determine if parallel decompression is necessary or not.
\end{itemize}

\section{IO test}

Interleaved writing of 4 files of 1GB with 4k block size:
\begin{tabular}{llrrr}
\hline
&&write&par&seq
\\\hline
tweety & ext3 & 22.22 & 9.32 & 24.56
\\\hline
tweety & xfs & 23.28 & 8.58 & 24.53
\\\hline
tweety & vfat & 5.89 & 14.75 & 6.43
\\\hline
\end{tabular}

Tweety single 4GB file yields write 19.39 MB/s and read 24.18 MB/s.


\end{document}

\section{Oude aantekeningen}

The key to high bandwidth is to avoid seeking.

In a single user scenario seeking can be avoided completely.
In a multi user scenario this is impossible.

In a multi user scenarios the best one can do is use
large blocks.

The idea is to work towards a cached distributed logical
volume manager (DLVM) that works on the principle
of reading/writing entire extents.
This is very similar to the Amoeba/bullet file system
which can only do load/store operations on entire files.

The correct size of a cluster depends on the disk system.
If you have a 4+1 RAID 5 then 256kB is reasonable.
If you have a 10+2 RAID 6 then 640kB is better.
This means that when copying a file, we may have to
re-block (and possibly defrag) on-the-fly.

Only writing clusters is equivalent to writing
entire row is RAID: good for write bandwidth.

Each cluster contains:
 - multiple data blocks.
 - a index of data blocks.
 - a system meta-info area.

It is not a good idea to put the meta records in the
same place in every block: they could end up on
a single disk of an array.

But it could be solved by defining a rotation scheme that
ensures that meta info is distributed fairly.
This could go wrong in the case of sparse files,
if the holes in the spare files are in sync with the rotation.
It could also go wrong if there are N+1 disks, N workers and
a rotation of 1.
So maybe we should rotate in groups:
with N workers: rotate first N clusters by 0.
rotate second N clusters by 1, etc.


\end{document}

