\documentclass{cwiarticle}

\usepackage{tabularx}

\title{MPI tools for state space generation and reduction.}
\author{Stefan Blom}

\begin{document}
\maketitle

\begin{abstract}
In this document we describe how to use the MPI based state space generator and
reducers.
\end{abstract}

\tableofcontents

\section{Introduction}

\section{Using the tools with LAM-MPI and PBS.}

When LAM is booted it needs to be told on which nodes it must start.
If LAM is compiled with PBS suppor

If LAM is PBS aware then LAM is started with the command
\begin{verbatim}
lamboot
\end{verbatim}
If it is not then we must ourselves use the list of nodes given by PBS:
\begin{verbatim}
ssh-key-check `cat $PBS_NODEFILE | sort | uniq`
lamboot $PBS_NODEFILE
\end{verbatim}
The command \verb+ssh-key-check+ is a script (see Table. \ref{ssh-key-check}) which
checks the SSH keys of the nodes involved. This will stop the script
from failing if an SSH key changes.

\begin{table}
\begin{verbatim}
#!/bin/bash
for i in $* ; do
        echo checking keys of $i
        ip=`ypmatch $i hosts | awk '{print $1}'`
        echo IP is $ip
        oldkey=`grep ^$i,$ip ~/.ssh/known_hosts`
        newkey=`ssh-keyscan -t rsa $i,$ip 2>/dev/null`
        if [ "$oldkey" = "$newkey" ] ; then
                echo "keys are OK"
        else
                echo "new or different key, replacing"
                /bin/cp ~/.ssh/known_hosts ~/.ssh/known_hosts.in.$$
                grep -v ^$i,$ip ~/.ssh/known_hosts.in.$$ > ~/.ssh/known_hosts.out.$$
                echo $newkey >> ~/.ssh/known_hosts.out.$$
                /bin/mv ~/.ssh/known_hosts.out.$$ ~/.ssh/known_hosts
                /bin/rm ~/.ssh/known_hosts.in.$$
        fi
done
\end{verbatim}
\caption{The {\tt ssh-key-check} script.}\label{ssh-key-check}
\end{table}

\section{State space generation}

\subsection*{Description}

The DIR format used for the tools has provisions for writing
transitions, parent information, state information and lists of
interesting states. The default is to write the transitions only.
This behaviour can be changed with the following options:
\\\begin{tabularx}{\textwidth}{lX}
\verb+-nolts+   &  {\em Disable writing the transitions.}
\\
\verb+-pi+  & {\em Enable writing of parent information.} Upon visiting a state for the first time we write the state from which the state was visited to disk. This information allows
us to find a shortest path to any state.
\\
\verb+-dlk+ & {\em Enable writing of deadlock information.} Detect deadlocks and write their state numbers
into a files. If traces to deadlocks are needed then the \verb+-pi+ should be given as well.
\\
\verb+-si+  & {\em Enable writing of state information information.} After completing state space generation, the entire state database is dumped to disk.
\end{tabularx}
The default output directory is derived from the name of the inpout LPO. This is done by stripping
the tbf extension and replacing it with dir. The output directory is always created with respect to the current working directory, even if the input LPO is in a completely different location. The output directory can be changed with the \verb+-dir+ option.

\medskip

The are also a number of important fine tuning options:
\\\begin{tabularx}{\textwidth}{lX}
\verb+-nolb+  & {\em Disable load balancing.} By default the MPI instatiator will use dynamic load balancing:
if one worker is finished it will ask the others for states to explore. This option has no real use, except
benchmarking, but was not removed because
it may be needed for a feature which is inompatible with load balancing.
\\
\verb+-nice+ & {\em All workers will set nice.} Useless in a dedicated cluster, but very useful
if you have to borrow workstations from collegues.
\\
\verb+-seq-rw+ & {\em Perform initialisation of rewriters sequentially
                 rather than in parallel.} The new rewriters of the $\mu$CRL toolset (rww and jitty) can be initialized in parallel. The old rw rewriters use a temporary file with a fixed name and must therefore be initialized sequentially.
\\
\verb+-master-no-step+ & {\em Instruct master to act as database only.}
The first worker holds the master database for transition labels and terms. In some cases
there are too many lokups. In such a case it is more efficient if the master behaves as a dedicated database
rather than an interleaved explorer/database.
\\
\verb+-cmp+ & {\em Compare term by mean of \verb+eq+.} By default terms are considered equal if
they are syntactically equivalent. This options turns on comparing terms by means of \verb+eq+ functions.
If you have a datatype, which allows non-unique representations (e.g. represeting a set with an unordered list) then this option will normalize the representation, thus reducing the state space on-the-fly.
\end{tabularx}

\subsection*{Known problems}

The state space generator uses the assumption that each parameter in the state vector
will have only a few different values. A typical example where this assumption does not hold
is the model of a security protocol with intruder. The intruder has a knowledge database
and this knowledge database takes many different values. This results in bad performance
both in memory use and in time. The best way to resolve this problem is to
identify the offending parameter and use \verb+structelm+ on it.

If the problem cannot be resolved then the result is not only higher memory use but also
a lot of parameter lookup requests to the master worker. If this is the case then giving
the \verb+-master-no-step+ is another way to improve efficiency. Because the latency of the
requests gets lower and the efficiency of the other workers is improved.

\section{State space reduction}

\subsection*{Description}

We have tools for distributed strong and branching bisimulation reduction.
The command for strong bisimulation reduction is
\begin{verbatim}
mpirun <nodespec> mpi_min_s <input> <output>
\end{verbatim}
The command for branching bisimulation reduction is
\begin{verbatim}
mpirun <nodespec> mpi_min_s <input> <output>
\end{verbatim}
The input format of both tools is the \verb+dir+ format.
The output format is a pre-release version of parallel BCG.
The input is indicated by the directory name.
The output is indicated with a prefix for the BCG files.

\subsection*{Known problems}

Both tools use a datastructures for signature sets whose memory consumption
depends on the orders in which the signature is built. If the signatures
are built in a nice order then the memory use for a signature is linear in the size of the
signature. If they are built in a bad order the memory use becomes exponential
in the size of the signature.

This problem can be solved in two ways. First, by implementing a garbage collection mechanism
the memory use becomes linear. Second, for strong bisimulation reduction and branching bisimulation
reduciton of $\tau$-cycle free state space it is possible to reimplement the tools using the
data structures of \verb+ltsmin+ which are linear.

\section{Conversion tools.}

There are several crude yet effective conversion tools for the distributed tools.
They are all sequential and stream based (they do not load the LTS into memory like \verb+ltscp+).

\subsection*{\tt bcg2dir}

This tools will transform a given BCG file into a dir format directory.
\begin{verbatim}
bcg2dir bcgfile segment_count dirname
\end{verbatim}

\subsection*{\tt dir2bcg}

This tool will transform a given dir format directory into a BCG file.
\begin{verbatim}
dir2bcg dir bcgfile
\end{verbatim}

\subsection*{\tt pbcg2dir}

This tool will convert the BCG files comprising a parallel BCG file
into a dir directory.
\begin{verbatim}
pbcg2dir bcgfile1 ... bcgfileN dirname
\end{verbatim}

\subsection*{\tt dir2pbcg}

This tool will convert a dir directory into BCG files comprising a parallel BCG file.
\begin{verbatim}
dir2pbcg dir bcgfile1 ... bcgfileN
\end{verbatim}

\section{Tutorial.}

To see how the tools are used. Let us consider BRP as an example.
First copy brp.mcrl to the current directory.

Linearize the specification:
\begin{verbatim}
mcrl -regular -nocluster brp.mcrl
\end{verbatim}

Mark confluent summands:
\begin{verbatim}
confcheck -mark brp.tbf > brp.c.tbf
\end{verbatim}

In the case of LAM MPI start the deamons:
\begin{verbatim}
lamboot
\end{verbatim}

Generate and reduce the state space:
\begin{verbatim}
mpirun -np 2 inst-mpi -alt rww brp.tbf
mpirun -np 2 mpi_min_b brp.dir brp_b
pbcg2dir brp_b-0.bcg brp_b-1.bcg brp_b.dir
\end{verbatim}

Generate and reduce the state space with on-the-fly reduction:
\begin{verbatim}
mpirun -np 2 inst-mpi -alt rww -conf-compute ctau brp.c.tbf
mpirun -np 2 mpi_min_b brp.c.dir brp_c_b
pbcg2dir brp_c_b-0.bcg brp_c_b-1.bcg brp_c_b.dir
\end{verbatim}

In the case of LAM MPI stop the deamons:
\begin{verbatim}
lamhalt
\end{verbatim}

\section{Future work}

\subsection*{Stream based LTS IO library}

Having separate conversion tools is OK as long as there are only a few formats
to be supported. To support the full range of formats, we will need a stream based
library. Moreover, this would enable tools which generate lists of transitions to write
all known formats.

\subsection*{(Distributed) in-memory LTS manipulation library}

Part of the succes of \verb+ltsmin+ as a development platform is the
fact that it is based on a crude sequential in-memory LTS manipulation library.
We need to clean it up and build support for distributed work into it.

\end{document}
